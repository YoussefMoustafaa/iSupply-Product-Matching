{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from symspellpy import SymSpell\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GRU, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Product Matching Dataset.xlsx\" , sheet_name=\"Dataset\")\n",
    "# df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words(\"arabic\")) | set(stopwords.words(\"english\"))\n",
    "\n",
    "# # text_column = df[\"seller_item_name\"].astype(str)  # Ensure text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qalsadi.lemmatizer import Lemmatizer\n",
    "\n",
    "# Initialize the Arabic lemmatizer\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "def preprocessing(text):\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove Arabic diacritics (tashkeel)\n",
    "    text = re.sub(r\"[\\u064B-\\u065F]\", \"\", text)\n",
    "    \n",
    "    # Remove non-Arabic characters except numbers\n",
    "    text = re.sub(r'[^\\u0621-\\u064A0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Standardize specific terms\n",
    "    text = re.sub(r'قرص|\\bق\\b|\\bك\\b|اقراص|كبسوله', 'كبسول', text)\n",
    "    text = re.sub(r'([\\u0600-\\u06FF])\\1+', r'\\1', text)  # Remove Arabic repetition\n",
    "    text = re.sub(r'[إأآ]', 'ا', text)\n",
    "    text = re.sub(r'ى', 'ي', text)\n",
    "    text = re.sub(r'ة', 'ه ', text)\n",
    "    text = re.sub(r'ؤ', 'و', text)\n",
    "    text = re.sub(r'ئ', 'ي', text)\n",
    "    \n",
    "    # Separate numbers that stick to Arabic/English words\n",
    "    text = re.sub(r\"(\\d+)([a-zA-Z\\u0600-\\u06FF]+)\", r\"\\1 \\2\", text)  # Number followed by Arabic/English\n",
    "    text = re.sub(r\"([a-zA-Z\\u0600-\\u06FF]+)(\\d+)\", r\"\\1 \\2\", text)  # Arabic/English followed by number\n",
    "    \n",
    "    # Remove standalone Arabic/English characters (but not numbers)\n",
    "    text = re.sub(r\"\\b[^\\W\\d]\\b\", \"\", text)\n",
    "    \n",
    "    # Remove specific unwanted phrases\n",
    "    text = re.sub(r'\\b(?:سعر جديد|سعر|قديم|س جديد|س جدي|س ج|ركز)\\b', '', text)\n",
    "    text = re.sub(r'مرهم|اكريم', 'كريم', text)\n",
    "    text = re.sub(r'مليجرام|\\bم\\b|مجم', 'مجم', text)\n",
    "    text = re.sub(r'جرام|جم', 'جم', text)\n",
    "    text = re.sub(r'شرائط|شريطين', 'شريط', text)\n",
    "    text = re.sub(r'امبولات|امبوله|حقن', 'امبول', text)\n",
    "    text = re.sub(r'لبوس|لبوس اطفال', 'اقماع', text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Lemmatize each token\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join the lemmatized tokens back into a single string\n",
    "    lemmatized_text = \" \".join(lemmatized_tokens)\n",
    "    \n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\qalsadi\\analex.py:109: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  \"([\\w%s\\s]+)\" % (u\"\".join(araby.TASHKEEL), ), re.UNICODE)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_seller_item_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseller_item_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[42], line 51\u001b[0m, in \u001b[0;36mpreprocessing\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     48\u001b[0m tokens \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Lemmatize each token\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m lemmatized_tokens \u001b[38;5;241m=\u001b[39m [\u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Join the lemmatized tokens back into a single string\u001b[39;00m\n\u001b[0;32m     54\u001b[0m lemmatized_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lemmatized_tokens)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\qalsadi\\lemmatizer.py:159\u001b[0m, in \u001b[0;36mLemmatizer.lemmatize\u001b[1;34m(self, word, return_pos, pos)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, return_pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    Lemmatize text\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    @param text: input text\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    @type text: unicode\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lemmas:\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lemmas[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\qalsadi\\lemmatizer.py:148\u001b[0m, in \u001b[0;36mLemmatizer.lemmatize_text\u001b[1;34m(self, text, return_pos, pos)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, return_pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m    Lemmatize text\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    @param text: input text\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    @type text: unicode\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     result    \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     stemnodelist  \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyze(result)\n\u001b[0;32m    150\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_lemmas(stemnodelist, return_pos\u001b[38;5;241m=\u001b[39mreturn_pos, pos\u001b[38;5;241m=\u001b[39mpos)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\qalsadi\\analex.py:337\u001b[0m, in \u001b[0;36mAnalex.check_text\u001b[1;34m(self, text, mode)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_word(\n\u001b[0;32m    335\u001b[0m )  \u001b[38;5;66;03m# a ghost function to count words check function calls\u001b[39;00m\n\u001b[0;32m    336\u001b[0m guessedtag \u001b[38;5;241m=\u001b[39m list_guessed_tag[i]\n\u001b[1;32m--> 337\u001b[0m one_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguessedtag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m stemmed_one_data_list \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    339\u001b[0m     stemmedword\u001b[38;5;241m.\u001b[39mStemmedWord(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m one_data_list\n\u001b[0;32m    340\u001b[0m ]\n\u001b[0;32m    341\u001b[0m resulted_data\u001b[38;5;241m.\u001b[39mappend(stemmed_one_data_list)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\qalsadi\\analex.py:430\u001b[0m, in \u001b[0;36mAnalex.check_word\u001b[1;34m(self, word, guessedtag)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;66;03m#if word is noun\u001b[39;00m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlight_tag(word) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonnoun\u001b[39m\u001b[38;5;124m\"\u001b[39m:                \n\u001b[1;32m--> 430\u001b[0m             resulted_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_word_as_noun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_nm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(resulted_data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;66;03m#print (u\"1 _unknown %s-%s\"%(word, word_nm)).encode('utf8')\u001b[39;00m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;66;03m#check the word as unkonwn\u001b[39;00m\n\u001b[0;32m    435\u001b[0m     resulted_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_word_as_unknown(word_nm)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\qalsadi\\analex.py:656\u001b[0m, in \u001b[0;36mAnalex.check_word_as_noun\u001b[1;34m(self, noun)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_word_as_noun\u001b[39m(\u001b[38;5;28mself\u001b[39m, noun):\n\u001b[0;32m    649\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;124;03m    Analyze the word as noun.\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03m    @param noun: the input word.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m    @rtype: list.\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnounstemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstemming_noun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoun\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\qalsadi\\stem_noun.py:205\u001b[0m, in \u001b[0;36mNounStemmer.stemming_noun\u001b[1;34m(self, noun_in)\u001b[0m\n\u001b[0;32m    203\u001b[0m         word_seg_l3 \u001b[38;5;241m=\u001b[39m word_seg\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    204\u001b[0m         word_seg_l3[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m noun_tuple[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocalized\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 205\u001b[0m         word_seg_l3[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoun_tuple\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnoun_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m         tmp_list\u001b[38;5;241m.\u001b[39mappend(word_seg_l3)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter lookup dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df[\"cleaned_seller_item_name\"] = df[\"seller_item_name\"].astype(str).apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Price\n",
    "scaler = StandardScaler()\n",
    "df[\"scaled_price\"] = scaler.fit_transform(df[[\"price\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of price column\n",
    "df[\"price\"].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove outliers\n",
    "df = df[df[\"price\"] < 1000]\n",
    "# plot boxplot to check for outliers\n",
    "df[\"price\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33990"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df_2 = df.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['scaled_price'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Feature and Target\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcleaned_seller_item_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscaled_price\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m Y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msku\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Label Encoding for SKU\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['scaled_price'] not in index\""
     ]
    }
   ],
   "source": [
    "# Feature and Target\n",
    "X = df[[\"cleaned_seller_item_name\", \"scaled_price\"]]\n",
    "Y = df[\"sku\"]\n",
    "\n",
    "# Label Encoding for SKU\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"encoded_sku\"] = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 29ms/step - accuracy: 0.1191 - loss: 4.7483 - val_accuracy: 0.8717 - val_loss: 1.0730\n",
      "Epoch 2/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 21ms/step - accuracy: 0.8630 - loss: 0.9335 - val_accuracy: 0.9743 - val_loss: 0.2818\n",
      "Epoch 3/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 22ms/step - accuracy: 0.9615 - loss: 0.3295 - val_accuracy: 0.9793 - val_loss: 0.1942\n",
      "Epoch 4/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 22ms/step - accuracy: 0.9747 - loss: 0.2020 - val_accuracy: 0.9793 - val_loss: 0.1604\n",
      "Epoch 5/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 22ms/step - accuracy: 0.9785 - loss: 0.1450 - val_accuracy: 0.9800 - val_loss: 0.1511\n",
      "Epoch 6/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 22ms/step - accuracy: 0.9793 - loss: 0.1231 - val_accuracy: 0.9807 - val_loss: 0.1459\n",
      "Epoch 7/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 24ms/step - accuracy: 0.9817 - loss: 0.1055 - val_accuracy: 0.9804 - val_loss: 0.1487\n",
      "Epoch 8/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 22ms/step - accuracy: 0.9839 - loss: 0.0888 - val_accuracy: 0.9812 - val_loss: 0.1468\n",
      "Epoch 9/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 22ms/step - accuracy: 0.9836 - loss: 0.0877 - val_accuracy: 0.9817 - val_loss: 0.1516\n",
      "Epoch 10/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9835 - loss: 0.0860 - val_accuracy: 0.9816 - val_loss: 0.1497\n",
      "Epoch 11/100\n",
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 22ms/step - accuracy: 0.9856 - loss: 0.0764 - val_accuracy: 0.9819 - val_loss: 0.1478\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.1559\n",
      "RNN Model Accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "# Tokenization for RNN\n",
    "num_words = 5000\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X[\"cleaned_seller_item_name\"])\n",
    "sequences = tokenizer.texts_to_sequences(X[\"cleaned_seller_item_name\"])\n",
    "\n",
    "# Padding\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "x_padded = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# Train-Test Split for RNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_padded, df[\"encoded_sku\"], test_size=0.2, random_state=42, stratify=df[\"encoded_sku\"], shuffle=True)\n",
    "\n",
    "# Build Improved RNN Model\n",
    "rnn_model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=256, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(GRU(32)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(len(label_encoder.classes_), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "rnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(learning_rate=0.0005), metrics=[\"accuracy\"])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train RNN Model\n",
    "rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate RNN Model\n",
    "loss, accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "print(f\"RNN Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_seller_item_name\"] = df[\"seller_item_name\"].astype(str).apply(preprocessing)\n",
    "scaler = StandardScaler()\n",
    "df[\"scaled_price\"] = scaler.fit_transform(df[[\"price\"]])\n",
    "X = df[[\"cleaned_seller_item_name\", \"scaled_price\"]]\n",
    "Y = df[\"sku\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'شوجارلو بلس 1000 50 مج 30 كبسول الاسراء'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text  = preprocessing(\"تورسيرتيك5مجم\")\n",
    "# text  = preprocessing(\"تورسيرتيك 5مجم\")\n",
    "# text  = preprocessing(\"SPANIELA MR35MG30TAB\")\n",
    "# text  = preprocessing(\"شوجارلو بلس 1000/50مج30قرص س ج/الاسراء\")\n",
    "# text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build SymSpell Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column 'marketplace_product_name_ar' not found in dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dataset_filename):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found! Check the filename and path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m dict_file \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dictionary_from_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m sym_spell \u001b[38;5;241m=\u001b[39m initialize_symspell(dict_file)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Example: Input Medicine Name and Correct It\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[45], line 50\u001b[0m, in \u001b[0;36mbuild_dictionary_from_dataset\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Ensure column exists\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarketplace_product_name_ar\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarketplace_product_name_ar\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in dataset!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarketplace_product_name_ar\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna():\n\u001b[0;32m     53\u001b[0m     normalized_product \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(product)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mValueError\u001b[0m: Column 'marketplace_product_name_ar' not found in dataset!"
     ]
    }
   ],
   "source": [
    "# from symspellpy import SymSpell\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     \"marketplace_product_name_ar\": [\"منتج\", \"منتج\", \"منتج جديد\", \"منج جديد\"],  # Example Data\n",
    "#     \"cleaned_seller_item_name\": [\"منتج جد\", \"منتج جدي\", \"منتج جديي\", \"منج جد\"]\n",
    "# })\n",
    "\n",
    "# # 1. Create Word Frequency Dictionary\n",
    "# word_freq_dict = {}\n",
    "# for product in df[\"marketplace_product_name_ar\"].dropna():\n",
    "#     normalized_product = str(product).strip()\n",
    "#     word_freq_dict[normalized_product] = word_freq_dict.get(normalized_product, 0) + 1\n",
    "\n",
    "# # Save Dictionary (Ensure tab separation)\n",
    "# dict_file = \"product_dictionary.txt\"\n",
    "# with open(dict_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     for word, freq in word_freq_dict.items():\n",
    "#         f.write(f\"{word}\\t{freq}\\n\")  # Use TAB instead of SPACE\n",
    "\n",
    "# # 2. Initialize SymSpell\n",
    "# sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "\n",
    "# # Load Dictionary and Check if Loaded Correctly\n",
    "# if not sym_spell.load_dictionary(dict_file, term_index=0, count_index=1, encoding=\"utf-8\"):\n",
    "#     print(\"Dictionary loading failed!\")\n",
    "\n",
    "# # 3. Apply SymSpell Correction\n",
    "# def correct_text(text):\n",
    "#     suggestions = sym_spell.lookup(text, verbosity=0, max_edit_distance=2)  # Use verbosity=0 for best match\n",
    "#     return suggestions[0].term if suggestions else text\n",
    "\n",
    "# df[\"corrected_seller_item_name\"] = df[\"cleaned_seller_item_name\"].apply(correct_text)\n",
    "\n",
    "# # Show Results\n",
    "# print(df[[\"cleaned_seller_item_name\", \"corrected_seller_item_name\"]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sku', 'marketplace_product_name_ar', 'seller_item_name', 'price']\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# dataset_filename = \"Product Matching Dataset.xlsx\"  # Your file name\n",
    "\n",
    "# df = pd.read_excel(dataset_filename, sheet_name=\"Dataset\")  # Load Excel file\n",
    "# print(df.columns.tolist())  # Print all column names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded_sku\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded_sku\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_train_tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df['encoded_sku'], test_size=0.2, random_state=42, stratify=df['encoded_sku'], shuffle=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 21ms/step - accuracy: 0.1221 - loss: 4.7405 - val_accuracy: 0.8558 - val_loss: 1.0872\n",
      "Epoch 2/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.8361 - loss: 0.9156 - val_accuracy: 0.9420 - val_loss: 0.2969\n",
      "Epoch 3/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.9329 - loss: 0.3006 - val_accuracy: 0.9500 - val_loss: 0.2200\n",
      "Epoch 4/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.9475 - loss: 0.1839 - val_accuracy: 0.9501 - val_loss: 0.2161\n",
      "Epoch 5/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.9503 - loss: 0.1493 - val_accuracy: 0.9528 - val_loss: 0.2165\n",
      "Epoch 6/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.9564 - loss: 0.1233 - val_accuracy: 0.9559 - val_loss: 0.2106\n",
      "Epoch 7/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.9583 - loss: 0.1090 - val_accuracy: 0.9558 - val_loss: 0.2159\n",
      "Epoch 8/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.9610 - loss: 0.1031 - val_accuracy: 0.9545 - val_loss: 0.2266\n",
      "Epoch 9/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.9608 - loss: 0.0951 - val_accuracy: 0.9566 - val_loss: 0.2254\n",
      "Epoch 10/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.9618 - loss: 0.0940 - val_accuracy: 0.9562 - val_loss: 0.2317\n",
      "Epoch 11/100\n",
      "\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 28ms/step - accuracy: 0.9615 - loss: 0.0912 - val_accuracy: 0.9562 - val_loss: 0.2347\n",
      "\u001b[1m784/784\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.2083\n",
      "RNN Model Accuracy: 0.9559\n"
     ]
    }
   ],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# df[\"encoded_sku\"] = label_encoder.fit_transform(df[\"sku\"])\n",
    "\n",
    "# # Tokenization for RNN\n",
    "# num_words = 5000\n",
    "# tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "# tokenizer.fit_on_texts(df[\"cleaned_seller_item_name\"])\n",
    "# sequences = tokenizer.texts_to_sequences(df[\"cleaned_seller_item_name\"])\n",
    "\n",
    "# # Padding\n",
    "# max_length = max(len(seq) for seq in sequences)\n",
    "# x_padded = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# # Train-Test Split for RNN\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_padded, df[\"encoded_sku\"], test_size=0.3, random_state=42)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_padded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# rnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# # Early Stopping\n",
    "# early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Train RNN Model\n",
    "# rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# loss, accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "# print(f\"RNN Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Label Encoding for SKU\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"encoded_sku\"] = label_encoder.fit_transform(df[\"sku\"])\n",
    "\n",
    "# # Tokenization for RNN\n",
    "# num_words = 5000\n",
    "# tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "# tokenizer.fit_on_texts(X)\n",
    "# sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# # Padding\n",
    "# max_length = max(len(seq) for seq in sequences)\n",
    "# x_padded = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# Train-Test Split for RNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_padded, df[\"encoded_sku\"], test_size=0.3, random_state=42)\n",
    "\n",
    "# Build Improved RNN Model\n",
    "rnn_model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=256, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(GRU(32)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(len(label_encoder.classes_), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# rnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(learning_rate=0.0005), metrics=[\"accuracy\"])\n",
    "\n",
    "# # Early Stopping\n",
    "# early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Train RNN Model\n",
    "# rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# loss, accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "# print(f\"RNN Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "1469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "def predict_sku(medicine_name, threshold=0.5):\n",
    "    # Preprocess the input name\n",
    "    cleaned_text = preprocessing(medicine_name)\n",
    "    \n",
    "    # Convert to sequence\n",
    "    seq = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    padded_seq = pad_sequences(seq, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    # Get model predictions\n",
    "    predictions = rnn_model.predict(padded_seq)[0]\n",
    "    \n",
    "    # Get highest probability SKU\n",
    "    max_prob = np.max(predictions)\n",
    "    predicted_label = np.argmax(predictions)\n",
    "\n",
    "    # If confidence is low, return \"unknown\"\n",
    "    if max_prob < threshold:\n",
    "        return \"unknown\"\n",
    "\n",
    "    # Convert label back to SKU\n",
    "    return label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "# # Example Predictions\n",
    "# print(predict_sku(\"بانادول اكسترا\"))  # Should return the correct SKU or \"unknown\"\n",
    "# print(predict_sku(\"شوجارلو بلس 50/1000  30\"))  # Should return \"unknown\"\n",
    "# print(predict_sku(\"GLIPTUS PLUS 50/1000 MG 30 TAB\"))  # Should return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m784/784\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "probabilities = rnn_model.predict(X_test)\n",
    "\n",
    "confidence_scores = np.max(probabilities, axis=1)\n",
    "\n",
    "predicted_indices = np.argmax(probabilities, axis=1)\n",
    "\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_indices)\n",
    "\n",
    "confidence_threshold = 0.85\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    confidence = confidence_scores[i]\n",
    "    predicted_class = predicted_labels[i]\n",
    "\n",
    "    if confidence < confidence_threshold:\n",
    "        predicted_class = \"Unknown\"\n",
    "\n",
    "    test_results.append({\n",
    "        'Predicted': predicted_class,\n",
    "        'Confidence': f\"{confidence:.2f}\"\n",
    "    })\n",
    "\n",
    "temp_df = pd.DataFrame(test_results)\n",
    "\n",
    "temp_df.head()\n",
    "df.to_csv(\"predict.csv\" , index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting farasa\n",
      "  Downloading Farasa-0.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading Farasa-0.0.1-py2.py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 645.7 kB/s eta 0:00:19\n",
      "   - -------------------------------------- 0.5/12.6 MB 645.7 kB/s eta 0:00:19\n",
      "   -- ------------------------------------- 0.8/12.6 MB 657.8 kB/s eta 0:00:18\n",
      "   -- ------------------------------------- 0.8/12.6 MB 657.8 kB/s eta 0:00:18\n",
      "   --- ------------------------------------ 1.0/12.6 MB 645.7 kB/s eta 0:00:18\n",
      "   --- ------------------------------------ 1.0/12.6 MB 645.7 kB/s eta 0:00:18\n",
      "   --- ------------------------------------ 1.0/12.6 MB 645.7 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 583.5 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 583.5 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 590.9 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 625.4 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 625.4 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 625.4 kB/s eta 0:00:18\n",
      "   ------ --------------------------------- 2.1/12.6 MB 611.7 kB/s eta 0:00:18\n",
      "   ------ --------------------------------- 2.1/12.6 MB 611.7 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 2.4/12.6 MB 607.3 kB/s eta 0:00:17\n",
      "   -------- ------------------------------- 2.6/12.6 MB 626.6 kB/s eta 0:00:16\n",
      "   -------- ------------------------------- 2.6/12.6 MB 626.6 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.9/12.6 MB 628.3 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.9/12.6 MB 628.3 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.9/12.6 MB 628.3 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 3.1/12.6 MB 615.2 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 3.1/12.6 MB 615.2 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 621.4 kB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 621.4 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 614.4 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 614.4 kB/s eta 0:00:15\n",
      "   ------------ --------------------------- 3.9/12.6 MB 618.2 kB/s eta 0:00:14\n",
      "   ------------ --------------------------- 3.9/12.6 MB 618.2 kB/s eta 0:00:14\n",
      "   ------------- -------------------------- 4.2/12.6 MB 613.8 kB/s eta 0:00:14\n",
      "   ------------- -------------------------- 4.2/12.6 MB 613.8 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 4.5/12.6 MB 611.5 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 4.5/12.6 MB 611.5 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 4.7/12.6 MB 618.7 kB/s eta 0:00:13\n",
      "   --------------- ------------------------ 5.0/12.6 MB 622.7 kB/s eta 0:00:13\n",
      "   --------------- ------------------------ 5.0/12.6 MB 622.7 kB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 623.8 kB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 623.8 kB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 622.5 kB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 622.5 kB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 622.5 kB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 622.5 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 5.8/12.6 MB 599.2 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 5.8/12.6 MB 599.2 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 6.0/12.6 MB 598.3 kB/s eta 0:00:11\n",
      "   ------------------- -------------------- 6.0/12.6 MB 598.3 kB/s eta 0:00:11\n",
      "   ------------------- -------------------- 6.3/12.6 MB 602.0 kB/s eta 0:00:11\n",
      "   ------------------- -------------------- 6.3/12.6 MB 602.0 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 6.6/12.6 MB 603.7 kB/s eta 0:00:10\n",
      "   -------------------- ------------------- 6.6/12.6 MB 603.7 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 6.8/12.6 MB 601.8 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 6.8/12.6 MB 601.8 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 601.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 601.7 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 601.6 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 601.6 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.6/12.6 MB 604.6 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.6/12.6 MB 604.6 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.9/12.6 MB 604.4 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 7.9/12.6 MB 604.4 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 8.1/12.6 MB 608.6 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 8.1/12.6 MB 608.6 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.6 MB 611.1 kB/s eta 0:00:07\n",
      "   -------------------------- ------------- 8.4/12.6 MB 611.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 8.7/12.6 MB 606.6 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 8.7/12.6 MB 606.6 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 611.1 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 611.1 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 609.4 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 609.4 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 614.2 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 614.2 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 9.7/12.6 MB 611.9 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 9.7/12.6 MB 611.9 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 10.0/12.6 MB 611.6 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 10.0/12.6 MB 611.6 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 10.2/12.6 MB 615.4 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 10.2/12.6 MB 615.4 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 10.5/12.6 MB 610.9 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 10.5/12.6 MB 610.9 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 613.5 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 613.5 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 616.4 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 616.4 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 615.9 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 615.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 11.5/12.6 MB 615.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.5/12.6 MB 615.6 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.8/12.6 MB 614.7 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.8/12.6 MB 614.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.1/12.6 MB 615.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 615.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 614.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 614.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 617.1 kB/s eta 0:00:00\n",
      "Installing collected packages: farasa\n",
      "Successfully installed farasa-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install farasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'farasa.segmenter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfarasa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmenter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FarasaSegmenter\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect_spelling_arabic\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     segmenter \u001b[38;5;241m=\u001b[39m FarasaSegmenter()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'farasa.segmenter'"
     ]
    }
   ],
   "source": [
    "# from farasa.segmenter import FarasaSegmenter\n",
    "\n",
    "# def correct_spelling_arabic(text):\n",
    "#     segmenter = FarasaSegmenter()\n",
    "#     corrected_text = segmenter.spellcheck(text)\n",
    "#     return corrected_text\n",
    "\n",
    "# # Test\n",
    "# text = \"فلكسوفان كيسول س ج ركزز\"\n",
    "# corrected_text = correct_spelling_arabic(text)\n",
    "# print(corrected_text)  # Output: \"فليكسوفان كبسول س ج ركزز\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
